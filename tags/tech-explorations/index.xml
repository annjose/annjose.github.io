<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tech-Explorations on Reflections</title>
    <link>https://annjose.com/tags/tech-explorations/</link>
    <description>Recent content in Tech-Explorations on Reflections</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2025. All rights reserved.</copyright>
    <lastBuildDate>Sun, 15 Dec 2024 12:15:21 -0700</lastBuildDate>
    <atom:link href="https://annjose.com/tags/tech-explorations/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chrome Side Panel</title>
      <link>https://annjose.com/post/chrome-side-panel/</link>
      <pubDate>Sun, 15 Dec 2024 12:15:21 -0700</pubDate>
      <guid>https://annjose.com/post/chrome-side-panel/</guid>
      <description>&lt;p&gt;Of late, I have been building and &lt;a href=&#34;https://annjose.com/post/browser-extn-intro/&#34;&gt;learning about browser extensions&lt;/a&gt; for a few projects. It was surprising to learn that there are many ways to build UI for these extensions and the most interesting one was the Side Panel UI available to Chrome extensions. In this post, I will talk about the Chrome side panel, how to build one and the advantages and limitations of using it.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-chrome-side-panel&#34;&gt;The Chrome side panel&lt;/h2&gt;&#xA;&lt;p&gt;It is a vertical panel that opens on either side of the browser window, providing quick access to your bookmarks, history, reading list, and Google Lens. It has a consistent layout and behavior across all websites. It was first introduced in Chrome in May 2023.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Compare AI Tools: LLMs and AI Assistants</title>
      <link>https://annjose.com/post/compare-ai-tools-llms/</link>
      <pubDate>Fri, 25 Oct 2024 17:22:33 -0700</pubDate>
      <guid>https://annjose.com/post/compare-ai-tools-llms/</guid>
      <description>&lt;p&gt;In this post, we will compare the most popular AI tools (frontier models and AI assistants) based on its capabilities, limitations and my personal experience of using them day-to-day.&lt;/p&gt;&#xA;&lt;p&gt;In order to accomodate the multiple dimensions of each model, this comparison is represented as mind maps in three parts:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Language models&lt;/strong&gt; - the most popular text-based models that are used for text-to-text content generation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;AI assistants&lt;/strong&gt; - the chatbots that are powered by one or more of the above models.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Other models&lt;/strong&gt; - other models that are used for text-to-image, text-to-voice or text-to-video use cases.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;At the end, we will also see the common set of tasks that we try to accomplish using these tools and recommendations on which tool is best for each task.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Browser Extensions: Part 2 - Advanced Concepts</title>
      <link>https://annjose.com/post/browser-extn-adv/</link>
      <pubDate>Thu, 05 Sep 2024 14:24:13 -0700</pubDate>
      <guid>https://annjose.com/post/browser-extn-adv/</guid>
      <description>&lt;p&gt;This is the second part of my blog series on browser extensions. Here, we&amp;rsquo;ll delve into advanced concepts including TypeScript integration, service workers, and programmatic script injection. For a solid foundation, I recommend reading &lt;a href=&#34;https://annjose.com/post/browser-extn-intro/&#34;&gt;Browser Extensions: Part 1 - Introduction&lt;/a&gt; before tackling these more complex topics.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-use-typescript-in-browser-extensions&#34;&gt;How to use TypeScript in browser extensions&lt;/h2&gt;&#xA;&lt;p&gt;By default, browser extensions use JavaScript as the programming language in the content scripts. However, TypeScript is more type safe and reliable to write the business logic. You can add TypeScript support to the extension project, but how do you do it? Chrome docs mention this as a one-liner as follows:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Browser Extensions: Part 1 - Introduction</title>
      <link>https://annjose.com/post/browser-extn-intro/</link>
      <pubDate>Wed, 04 Sep 2024 10:12:32 -0700</pubDate>
      <guid>https://annjose.com/post/browser-extn-intro/</guid>
      <description>&lt;p&gt;Imagine a world where every website adapts to your specific needs in real-time, securely and easily, without selling your data to third party companies. It will be cool, right? Yes and it is possible - thanks to &lt;strong&gt;Browser extensions&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In this post, we will learn about browser extensions - what they are, why you should build them and how to build them. We will conclude by looking at a few issues that come up frequently while building an extension and how to troubleshoot them. For those interested in advanced topics, check out Part 2 of this series - &lt;a href=&#34;https://annjose.com/post/browser-extn-adv/&#34;&gt;Browser Extensions: Part 2 - Advanced Concepts&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Perplexity AI: Insights from the CEO Aravind Srinivas</title>
      <link>https://annjose.com/post/perplexity-ai-ceo-insights/</link>
      <pubDate>Thu, 27 Jun 2024 20:21:42 -0700</pubDate>
      <guid>https://annjose.com/post/perplexity-ai-ceo-insights/</guid>
      <description>&lt;p&gt;Last week, I watched an interview of &lt;a href=&#34;https://www.linkedin.com/in/aravind-srinivas-16051987/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aravind Srinivas&lt;/a&gt;, the CEO of &lt;strong&gt;Perplexity AI&lt;/strong&gt; (&lt;a href=&#34;https://www.perplexity.ai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.perplexity.ai&lt;/a&gt;). It is a three-hour interview done by &lt;a href=&#34;https://www.linkedin.com/in/lexfridman/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lex Fridman&lt;/a&gt; where Aravind talked about the major breakthroughs in AI that brought us to LLMs, the mission of Perplexity, how the technology works, his vision of the future of search and web in general, and some valuable advice for startup founders and young people.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=e-gwvmhyU7A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fascinating interview&lt;/a&gt; - highly recommended for everyone to watch. Personally, it opened my eyes to the fact that Perplexity is very different from other chatbots - not only in how it works, but what it is trying to solve. So I started using it for a few days and was blown away by the results ðŸ’¯. I realized that this is one of the tools that gives you so much value that you cannot imagine going back to the way of doing it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Perplexity AI: A Deep Dive</title>
      <link>https://annjose.com/post/perplexity-ai/</link>
      <pubDate>Thu, 27 Jun 2024 16:19:12 -0700</pubDate>
      <guid>https://annjose.com/post/perplexity-ai/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Perplexity AI&lt;/strong&gt; (&lt;a href=&#34;https://www.perplexity.ai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.perplexity.ai&lt;/a&gt;) has been gaining attention in the world of chatbots and large language models. I had heard about it in a few forums and mentioned by industry leaders like Jensen Huang and Kelsey Hightower. In fact, I had created an account and tried it out a few times earlier this year, but didn&amp;rsquo;t take it much seriously.&lt;/p&gt;&#xA;&lt;p&gt;All that changed last week when I watched &lt;a href=&#34;https://www.youtube.com/watch?v=e-gwvmhyU7A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this recent interview&lt;/a&gt; of Perplexity CEO &lt;a href=&#34;https://www.linkedin.com/in/aravind-srinivas-16051987/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aravind Srinivas&lt;/a&gt; by &lt;a href=&#34;https://www.linkedin.com/in/lexfridman/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lex Fridman&lt;/a&gt;. It is a &lt;a href=&#34;https://www.youtube.com/watch?v=e-gwvmhyU7A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fascinating interview&lt;/a&gt; - highly recommended for everyone to watch, but personally, it opened my eyes to the fact that Perplexity is very different from other chatbots, not only in how it works, but what it is trying to solve. So I started using it for a few days and was blown away by the results ðŸ’¯. I realized that this is one of the tools that gives you so much value that you cannot imagine going back to the way of doing it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Apple of AI</title>
      <link>https://annjose.com/post/apple-intelligence/</link>
      <pubDate>Tue, 11 Jun 2024 20:14:23 -0700</pubDate>
      <guid>https://annjose.com/post/apple-intelligence/</guid>
      <description>&lt;p&gt;The standout feature unveiled at this week&amp;rsquo;s Apple WWDC 2024 event was &lt;a href=&#34;https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apple Intelligence&lt;/a&gt;, a personal intelligence system that will be integrated into multiple platforms - iOS 18, iPadOS 18 and macOS Sequoia.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-apple-intelligence&#34;&gt;What is Apple Intelligence?&lt;/h2&gt;&#xA;&lt;p&gt;Apple Intelligence comprises of multiple highly-capable and efficient generative models - large language models and diffusion models. These models include on-device models as well as server-based foundation models.&lt;/p&gt;&#xA;&lt;p&gt;The foundation models are trained on &lt;a href=&#34;https://github.com/apple/axlearn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apple&amp;rsquo;s open-source AXLearn library&lt;/a&gt; for deep learning, built on top of &lt;a href=&#34;https://jax.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JAX&lt;/a&gt; (Python library for accelerated computing and transformation) and &lt;a href=&#34;https://www.tensorflow.org/xla&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;XLA&lt;/a&gt; (Accelerated Linear Algebra, an open-source ML compiler). The branding of Apple Intelligence is intriguing, positioning it as Apple&amp;rsquo;s take on &amp;ldquo;AI&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Next.js - Migrate from Pages to App Router</title>
      <link>https://annjose.com/post/nextjs-migrate-pages-app-router/</link>
      <pubDate>Wed, 05 Jun 2024 12:42:25 -0700</pubDate>
      <guid>https://annjose.com/post/nextjs-migrate-pages-app-router/</guid>
      <description>&lt;p&gt;A few months ago, Next.js introduced &lt;strong&gt;App Router&lt;/strong&gt;, a new way to build React applications using the latest features like React Server components and streaming. This was included in Next.js version 13 and is meant to replace the &lt;strong&gt;Pages Router&lt;/strong&gt; eventually. I have been using the App Router for all my &lt;a href=&#34;https://annjose.com/post/learning-to-building/&#34;&gt;builder projects&lt;/a&gt; for a while now. In fact, I usually kicked off projects with the standard &lt;code&gt;create-next-app&lt;/code&gt; script that starts a new app from scratch.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPT-4 Turbo Vision: In Action</title>
      <link>https://annjose.com/post/gpt-4-vision-in-action/</link>
      <pubDate>Thu, 04 Apr 2024 21:12:23 -0700</pubDate>
      <guid>https://annjose.com/post/gpt-4-vision-in-action/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s been a few months since OpenAI announced &lt;a href=&#34;https://openai.com/index/new-models-and-developer-products-announced-at-devday&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT-4 Turbo with Vision&lt;/a&gt; a model capable of understanding images and answering questions based on visual input. Recently, I decided to leverage this in a real app and got valuable insights. This post is a quick summary of my learnings from that experience.&lt;/p&gt;&#xA;&lt;p&gt;We&amp;rsquo;ll explore how to use the model through ChatGPT and the Open AI API so that you can can integrate it into any application. I&amp;rsquo;ll wrap up with my observations from using this model in practice.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Run Code Llama 70B locally</title>
      <link>https://annjose.com/post/run-code-llama-70B-locally/</link>
      <pubDate>Mon, 29 Jan 2024 16:42:25 -0700</pubDate>
      <guid>https://annjose.com/post/run-code-llama-70B-locally/</guid>
      <description>&lt;p&gt;Today, &lt;a href=&#34;https://twitter.com/AIatMeta/status/1752013879532782075&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Meta AI announced&lt;/a&gt; they are releasing a new model &lt;strong&gt;Code Llama 70B&lt;/strong&gt;, a higher performing LLM to generate code. This was exciting news and we have to try it out immediately.&lt;/p&gt;&#xA;&lt;p&gt;In this post, I will do a walk-through of how to download and use the new model and how it compares to other code generating models like GPT-4.&lt;/p&gt;&#xA;&lt;p&gt;As usual, the best way to run the inference on any model locally is to run &lt;a href=&#34;https://ollama.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ollama&lt;/a&gt;. So let&amp;rsquo;s set up Ollama first.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPT-4 Technical Report Highlights</title>
      <link>https://annjose.com/post/gpt-4-tech-report-highlights/</link>
      <pubDate>Sun, 09 Apr 2023 12:59:18 -0800</pubDate>
      <guid>https://annjose.com/post/gpt-4-tech-report-highlights/</guid>
      <description>&lt;p&gt;OpenAI published the &lt;a href=&#34;https://cdn.openai.com/papers/gpt-4.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT-4 Technical Report&lt;/a&gt; on 27 Mar 2023. I wanted to read it immediately but was intimidated by the fact that it is a 100-page document. It turns out that it was not as difficult as I anticipated, it can be easily read over a weekend. The best part is that this report describes the key terminologies and methodologies used in the development of GPT-4. It&amp;rsquo;s always beneficial to obtain this information directly from the source.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Blog about ChatGPT in three different ways</title>
      <link>https://annjose.com/post/chatgpt-intro-3-ways/</link>
      <pubDate>Sun, 12 Feb 2023 22:57:43 -0800</pubDate>
      <guid>https://annjose.com/post/chatgpt-intro-3-ways/</guid>
      <description>&lt;p&gt;Ever since ChatGPT was released to the public last November, I&amp;rsquo;ve been eager to write a blog about it. However, the daunting prospect of facing a blank screen kept me from starting the task, and I found myself procrastinating. Today, I finally summoned the courage to begin writing, but with a few tweaks from my usual approach.&lt;/p&gt;&#xA;&lt;p&gt;Allow me to describe the meta experiment to understand how I can utilize ChatGPT to help me write the blog.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ChatGPT - An Introduction</title>
      <link>https://annjose.com/post/chatgpt-intro/</link>
      <pubDate>Sun, 12 Feb 2023 21:59:18 -0800</pubDate>
      <guid>https://annjose.com/post/chatgpt-intro/</guid>
      <description>&lt;p&gt;Over the past few months, ChatGPT has captured my attention through numerous forums, articles and AI experts. I am fascinated by this technology and learning more about it everyday. With this introductory post, I hope to share my knowledge and insights on ChatGPT - how it works, its capabilities and limitations, potential pitfalls, and future prospects.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note - Just for fun, I did an experiment to write two more versions of this post - one that was written by ChatGPT itself using a rough outline I provided, and another also written by ChatGPT, but imrprovised from my original post. Curious to see the results of the experiment? Head over to the meta post &lt;a href=&#34;https://annjose.com/post/chatgpt-intro-3-ways&#34;&gt;Blog about ChatGPT in three different ways&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ChatGPT Introduction - written by ChatGPT using Ann&#39;s outline</title>
      <link>https://annjose.com/post/chatgpt-intro-written-by-chatgpt-from-my-outline/</link>
      <pubDate>Sun, 12 Feb 2023 20:54:11 -0800</pubDate>
      <guid>https://annjose.com/post/chatgpt-intro-written-by-chatgpt-from-my-outline/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note - This post is written by ChatGPT expanding on the outline of my original post &lt;a href=&#34;https://annjose.com/post/chatgpt-intro&#34;&gt;An Introduction to ChatGPT&lt;/a&gt; - section by section. This is a fun exercise to demonstrate the potential of ChatGPT and how it can change how we create content, art and code. You can see the full results of the experiment at &lt;a href=&#34;https://annjose.com/post/chatgpt-intro-3-ways&#34;&gt;Blog about ChatGPT in three different ways&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Have you ever heard of ChatGPT? It&amp;rsquo;s a large language model that has taken the AI world by storm. But what exactly is ChatGPT and how does it work? This post will break down the basics and give you a good understanding of what it is, how it&amp;rsquo;s built and how it can be used in the real world.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ChatGPT Introduction - rewritten by ChatGPT from Ann&#39;s originial post</title>
      <link>https://annjose.com/post/chatgpt-intro-rewritten-by-chatgpt/</link>
      <pubDate>Sun, 12 Feb 2023 18:25:12 -0800</pubDate>
      <guid>https://annjose.com/post/chatgpt-intro-rewritten-by-chatgpt/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note - This post is written by ChatGPT by rewriting my original post &lt;a href=&#34;https://annjose.com/post/chatgpt-intro&#34;&gt;An Introduction to ChatGPT&lt;/a&gt; - section by section. This is a fun exercise to demonstrate the potential of ChatGPT and how it can change how we create content, art and code. You can see the full results of the experiment at &lt;a href=&#34;https://annjose.com/post/chatgpt-intro-3-ways&#34;&gt;Blog about ChatGPT in three different ways&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;As an avid learner and technology enthusiast, I have been following the advancements and discussions surrounding ChatGPT in various forums and sources. With this blog post, I aim to share my understanding of ChatGPT - what it is, its key benefits, potential limitations, and my vision of its future trajectory. Through my research and analysis of expert opinions, I hope to provide a comprehensive overview of this cutting-edge technology and its potential impact on our daily lives.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tinkering with VS Code, MacOS and C&#43;&#43;</title>
      <link>https://annjose.com/post/vscode-macos-cpp/</link>
      <pubDate>Mon, 29 Jun 2020 22:32:55 -0700</pubDate>
      <guid>https://annjose.com/post/vscode-macos-cpp/</guid>
      <description>&lt;p&gt;After a long time, I got the time to tinker with something fun and learn from it, thanks to the week-long break from work. The task at hand is to set up Visual Studio for Mac to compile/run/debug C++ programs. Why, you may wonder - for the past few months, I have been craving to learn something different and I was hooked when I saw the book &lt;a href=&#34;https://www.amazon.com/Data-Structures-Algorithms-Adam-Drozdek-dp-1133608426/dp/1133608426&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data Structures and Algorithms in C++&lt;/a&gt; by Adam Drozdek. I decided to read this book and learn from it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Swift 4.2 - What&#39;s New</title>
      <link>https://annjose.com/post/swift42-whats-new/</link>
      <pubDate>Fri, 12 Oct 2018 20:09:12 -0800</pubDate>
      <guid>https://annjose.com/post/swift42-whats-new/</guid>
      <description>&lt;p&gt;In this post, I would like to share what&amp;rsquo;s new in Swift 4.2. All the code displayed in this post is available at my GitHub repo &lt;a href=&#34;https://github.com/annjose/my-learnings/tree/master/Swift4.2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;my-learnings/Swift4.2&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;random-number-generation&#34;&gt;Random Number Generation&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Swift 4.2 added random number generator API to standard library. You can use it on &lt;code&gt;Int&lt;/code&gt;, &lt;code&gt;Double&lt;/code&gt;, &lt;code&gt;Float&lt;/code&gt;, &lt;code&gt;CGFloat&lt;/code&gt; and &lt;code&gt;Bool&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;It also provides a convenient API &lt;code&gt;randomElement&lt;/code&gt; which returns a random element from a sequence&lt;/li&gt;&#xA;&lt;li&gt;It also provides the APIs &lt;code&gt;shuffle&lt;/code&gt; and &lt;code&gt;shuffled&lt;/code&gt; to shuffle a sequence&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;&#34;&gt;&#xA;&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;&#34;&gt;&lt;code&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;1&#xA;&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;2&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;&#34;&gt;&lt;code class=&#34;language-swift&#34; data-lang=&#34;swift&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;randomInt&lt;/span&gt; = &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;Int&lt;/span&gt;.random(&lt;span style=&#34;color:#ff79c6&#34;&gt;in&lt;/span&gt;: &lt;span style=&#34;color:#bd93f9&#34;&gt;0.&lt;/span&gt;.&amp;lt;&lt;span style=&#34;color:#bd93f9&#34;&gt;10&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#8be9fd;font-style:italic&#34;&gt;randomElement&lt;/span&gt; = [&lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;one&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;two&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;three&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f1fa8c&#34;&gt;&amp;#34;four&amp;#34;&lt;/span&gt;].randomElement()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;h2 id=&#34;dynamic-member-lookup&#34;&gt;Dynamic Member Lookup&lt;/h2&gt;&#xA;&lt;p&gt;Swift 4.2 introduces a dot syntax to access custom subscripts; this is much cleaner than the earlier square bracket calls. The compiler evaluates the subscript call dynamically at runtime, but provides a cleaner syntax.&lt;/p&gt;</description>
    </item>
    <item>
      <title>TDD in Xcode Playground</title>
      <link>https://annjose.com/post/xcode-playgrounds-tdd/</link>
      <pubDate>Sun, 02 Apr 2017 02:02:31 -0700</pubDate>
      <guid>https://annjose.com/post/xcode-playgrounds-tdd/</guid>
      <description>&lt;p&gt;I use Xcode playground a lot in order to write code snippets - either to try out something that I read in a blog, or to demonstrate a code improvement that I want to suggest in a code review, or sometimes even to prototype a design before doing the full-blown implementation in Xcode project. During this experimentation phase, the correctness of the code was verified by analyzing the ouput displayed on the right-hand side column of the playground. This was really cumbersome and error-prone and I was hoping that there would be a better solution for this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Realm Mobile Platform</title>
      <link>https://annjose.com/post/realm-announces-mobile-platform/</link>
      <pubDate>Tue, 27 Sep 2016 08:22:02 -0700</pubDate>
      <guid>https://annjose.com/post/realm-announces-mobile-platform/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://realm.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Realm&lt;/a&gt; is a company that I respect a lot because of their support for mobile developers and the open nature nature of their offerings. Their easy-to-use, blazingly fast &lt;a href=&#34;https://realm.io/products/realm-mobile-database/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mobile database&lt;/a&gt; software supports all mobile platforms - iOS, Android, React Native and Xamarin, in Java, ObjC, Swift and C#.&#xA;That is why I am happy to see that today they announced &lt;a href=&#34;https://realm.io/blog/introducing-realm-mobile-platform/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Realm Mobile Platform&lt;/a&gt; that combines Realm client side database with server-side technology (Object Server as they call it). This platform provides the base infrastructure for mobile apps to support offline sync, that enables end users to interact with the app even when there is no network connection.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning - A new journey</title>
      <link>https://annjose.com/post/machine-learning-coursera/</link>
      <pubDate>Tue, 09 Aug 2016 20:05:54 -0700</pubDate>
      <guid>https://annjose.com/post/machine-learning-coursera/</guid>
      <description>&lt;p&gt;Few weeks ago, I started the &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Machine Learning course on Coursera&lt;/a&gt; by Andrew Ng of Stanford University. The course is great, learning a lot of new concepts. Sometimes it is hard, but it is really fun learning this new topic and brushing up the old Math lessons of Linear Algebra, matrix manipulation and derivatives.&lt;/p&gt;&#xA;&lt;p&gt;The course starts with the basics, including a primer on Linear Algebra (it is optional, but I took it anyway since it has been more than a decade when I learned it in college). At the end of each module, there is a quiz and programming assignments, which are interesting.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ReactNative in Visual Studio Code</title>
      <link>https://annjose.com/post/react-native-visual-studio-code/</link>
      <pubDate>Wed, 13 Apr 2016 21:22:02 -0700</pubDate>
      <guid>https://annjose.com/post/react-native-visual-studio-code/</guid>
      <description>&lt;p&gt;I have been thoroughly enjoying working on &lt;a href=&#34;https://facebook.github.io/react-native/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ReactNative&lt;/a&gt; projects, but was disappointed by the lack of a good debugging environment. I had tried multiple solutions like &lt;a href=&#34;http://nuclide.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nuclide&lt;/a&gt; (which I found it to be very slow), WebStorm with JSX plugins (which is mainly syntax recognition). So I had to always launch the app from Xcode/Android Studio, then attach Chrome Dev tools and keep switching between all three for debugging. This was frustrating, but there is hope&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Conversation as Interface</title>
      <link>https://annjose.com/post/conversation-as-interface/</link>
      <pubDate>Fri, 08 Apr 2016 20:47:54 -0700</pubDate>
      <guid>https://annjose.com/post/conversation-as-interface/</guid>
      <description>&lt;p&gt;The User Interface is going beyond UI and voice recognition to the new trend of using conversation as a new way to engage with customers, i.e. &lt;strong&gt;Conversation As Interface&lt;/strong&gt;. It is a more natural form of communication, especially for question-answer / interview experiences.&lt;/p&gt;&#xA;&lt;p&gt;Now there is an emerging trend of companies opening their chat bot API to third party developers. Facebook has been running &lt;a href=&#34;http://techcrunch.com/2016/01/05/facebook-messenger-bots/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;many experiments&lt;/a&gt; in their Messenger app allowing a few developers like Uber, Assist etc. to create chat bots. They are &lt;a href=&#34;http://techcrunch.com/2016/04/07/facebook-chatbots/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;expected to announce&lt;/a&gt; opening up the SDK to all in next weekâ€™s F8 conference. Microsoft &lt;a href=&#34;http://techcrunch.com/2016/03/30/microsoft-is-bringing-bots-to-skype-and-everywhere-else/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;released a Bot Framework&lt;/a&gt; in Build last week and this supports multiple channels â€“ Slack, SMS, Skype etc. Similarly, &lt;a href=&#34;http://techcrunch.com/2016/03/24/line-builds-out-its-chat-app-for-businesses-as-facebook-messenger-threat-looms-large/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Line&lt;/a&gt; announced its SDK.&lt;/p&gt;</description>
    </item>
    <item>
      <title>First post from Hugo</title>
      <link>https://annjose.com/post/first-post-from-hugo/</link>
      <pubDate>Mon, 27 Apr 2015 00:49:45 -0700</pubDate>
      <guid>https://annjose.com/post/first-post-from-hugo/</guid>
      <description>&lt;p&gt;This is my first blog post created by &lt;a href=&#34;http://gohugo.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo&lt;/a&gt;, a simple, fast and powerful blogging engine written in Go. Setting up my blog on Hugo was quick and easy; it took less than 4 hours.&lt;/p&gt;&#xA;&lt;p&gt;I have set this up such that I publish the content to &lt;a href=&#34;https://pages.github.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub pages&lt;/a&gt;, so the publish workflow is as simple as writing some Markdown and a git push. &lt;a href=&#34;http://gohugo.io/tutorials/github-pages-blog/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This is a good tutorial&lt;/a&gt; on how to do this.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
